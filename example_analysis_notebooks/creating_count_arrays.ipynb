{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12dbf983-0403-4298-97f6-8d9fef7130ac",
   "metadata": {},
   "source": [
    "# Creating Count Arrays\n",
    "\n",
    "Before the analysis of translation limitation can begin the data from the ribosome profiling experiments must be organized into count arrays. Count arrays are vectors that record the number of reads which map to each base pair or codon position along a transcript. The count arrays will be created inside of a Jupyter notebook which is running inside of the Plastid Conda environment set up in (!!!). Using Plastid to create the count arrays will allow for important adjustments to be made to the data such as applying the p-site offsets made in (!!!) and sub-setting the data to only look at the coding regions of the transcripts. The count arrays will be saved as simple csv tables which can be easily incorporated into further analyses in later sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0c3c45-529f-44f5-b0b8-790f72cc2825",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 17\n",
    "Load in the python libraries and functions necessary for this pipeline. This includes several functions from plastid and the contents of our setup_utils.py file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198212b6-3fce-430d-b93c-358ff2ae341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plastid import BAMGenomeArray,GTF2_TranscriptAssembler,Transcript\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plastid.plotting.plots import *\n",
    "import utilities as utils\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "077f1d84-caf2-46fe-9808-41fd7df37cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf_path = \"/home/keeganfl/Desktop/Work_Fall_2021/Protocol_test/genome/mouse/\"\n",
    "bam_path = \"/home/keeganfl/Desktop/Work_Fall_2021/Protocol_test/seleno_seq/\"\n",
    "save_path = \"/home/keeganfl/Desktop/Work_Fall_2021/Protocol_test/position_counts_seleno/\"\n",
    "p_site_path = \"/home/keeganfl/Desktop/Work_Fall_2021/data_tables/p-site_offsets/villar/\"\n",
    "condition1 = 'Trspfl'\n",
    "condition2 = 'control'\n",
    "samp_num = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83bd9b-3686-4901-92e1-8895346a8b32",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 18\n",
    "Load in the tables of P-site offsets created in the determining p-site offsets section using the Pandas function read_csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02aa05b-ae67-4f35-9f6f-122833357769",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_offsets_cond1 =pd.read_csv(p_site_path + condition1 + \"_RPF_\" + samp_num + \"_Aligned.toTranscriptome.out_p-site-offsets\", \n",
    "                      sep=\"\\t\")\n",
    "\n",
    "p_offsets_cond2 =pd.read_csv(p_site_path + condition2 + \"_RPF_\" + samp_num + \"_Aligned.toTranscriptome.out_p-site-offsets\", \n",
    "                      sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f80bcc-0220-490a-9c4c-441170ef5d28",
   "metadata": {},
   "source": [
    "### Step 19\n",
    "Load in a GTF genome annotation file into python using Plastid’s GTF2_TranscriptAssembler\n",
    "function. This function will load in the transcripts as an iterator of Plastid’s transcript type objects which we will then convert to a list using Python’s list function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6602aae6-6ecf-4e5f-b146-24a11b3409fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transcripts = list(GTF2_TranscriptAssembler(open(gtf_path + \"mm10.refGene.gtf\"),return_type=Transcript))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b848c-edde-4190-988d-133c2cc47e3c",
   "metadata": {},
   "source": [
    "### Step 20\n",
    "Load in the Bam file containing the Ribosome Profiling data as a Bam Genome Array using Plastid’s BamGenomeArray() function and map the reads to their corresponding P-sites via the VariableThreePrimeMapFactory custom function in setup_utils.py and Plastid’s set_mapping function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec43099-d578-40bc-8286-3a59cabc59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments_cond1 = BAMGenomeArray(bam_path + \"subset_\" + condition1 + \"_RPF_\" + samp_num + \".bam\")\n",
    "alignments_cond1.set_mapping(utils.VariableThreePrimeMapFactory(p_offsets=p_offsets_cond1))\n",
    "\n",
    "alignments_cond2 = BAMGenomeArray(bam_path + \"subset_\" + condition2 + \"_RPF_\" + samp_num + \".bam\")\n",
    "alignments_cond2.set_mapping(utils.VariableThreePrimeMapFactory(p_offsets=p_offsets_cond2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d88bebf-3416-4abb-9c0e-0881c8e8e2ee",
   "metadata": {},
   "source": [
    "### Step 21\n",
    "For each transcript object in our list use Plastid’s get_counts function to create a numpy array that contains the number of counts at each position in the transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc2d803-79d3-4707-a53b-e9db9df0d601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_vectors_cond1 = []\n",
    "count_vectors_cond2 = []\n",
    "\n",
    "for transcript in transcripts:\n",
    "    count_vectors_cond1.append(transcript.get_counts(alignments_cond1))\n",
    "    count_vectors_cond2.append(transcript.get_counts(alignments_cond2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11093c8-e9bb-4bfd-bb97-8c7dfafc602e",
   "metadata": {},
   "source": [
    "### Step 22\n",
    "Once the count arrays have been created the information on CDS regions contained in the transcript type objects can be used to alter the count arrays to only cover the CDS regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fba44882-1587-49df-8a82-0e145edeeaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_starts = []\n",
    "cds_ends = []\n",
    "\n",
    "for transcript in transcripts:\n",
    "    cds_starts.append(transcript.cds_start)\n",
    "    cds_ends.append(transcript.cds_end)\n",
    "\n",
    "for i in range(len(count_vectors_cond1)):\n",
    "    count_vectors_cond1[i] = list(count_vectors_cond1[i][cds_starts[i]:cds_ends[i]])\n",
    "    count_vectors_cond2[i] = list(count_vectors_cond2[i][cds_starts[i]:cds_ends[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188bf886-981c-4cd1-b92a-d71c74774e8e",
   "metadata": {},
   "source": [
    "### Step 23\n",
    "Use the add_gene_ids function from setup_utils.py to append the transcript ID and gene ID of each transcript to the start of the count vector.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49a4abcf-0ddb-45ce-bb02-874e0ec62fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.add_gene_ids(transcripts, count_vectors_cond1)\n",
    "utils.add_gene_ids(transcripts, count_vectors_cond2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc892c95-454f-48a3-a49c-249892a44396",
   "metadata": {},
   "source": [
    "### Step 24\n",
    "Filter out any count arrays that are of insufficient length or have insufficient read density. In this example, count arrays which were under 200 base pairs in length or which had a read density below 0.12 reads per base pair were filtered out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee2bc109-3153-4a4e-8b03-0e919ab1190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vec_cond1 = []\n",
    "filtered_vec_cond2 = []\n",
    "for vec_1, vec_2 in zip(count_vectors_cond1, count_vectors_cond2):\n",
    "    if len(vec_1) > 200 and sum(vec_1[2:])/len(vec_1[2:]) > 0.15 and sum(vec_2[2:])/len(vec_2[2:]) > 0.15:\n",
    "        filtered_vec_cond1.append(vec_1)\n",
    "        filtered_vec_cond2.append(vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ba682-aa91-4bb6-8d4c-7ae94b48ef2b",
   "metadata": {},
   "source": [
    "### Step 25\n",
    "Save the count arrays to be used in future notebooks. Use the custom save_count_positions function from setup_utils.py so that the count arrays are saved with a header that describes each column which it is easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8551e183-a82b-4273-a4f4-9642548c14c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_count_positions(filtered_vec_cond1, save_path + condition1 + \"_\" + samp_num + '_counts.csv')\n",
    "utils.save_count_positions(filtered_vec_cond2, save_path + condition2 + \"_\" + samp_num + '_counts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
